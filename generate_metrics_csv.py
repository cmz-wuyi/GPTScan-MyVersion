import os
import json
import csv

# ================= ğŸ”§ é…ç½®åŒºåŸŸ (Configuration) =================

# 1. è¾“å…¥ç›®å½• (Output Directory)
INPUT_OUTPUT_DIR = r"C:\Coding\CodingTool\PyCharm\PyCharm2025.2.1.1\Project\GPTScan\output"

# 2. è¾“å‡º CSV æ–‡ä»¶å
RESULT_CSV_PATH = "paper_comprehensive_report.csv"

# 3. çœŸå€¼é…ç½® (Ground Truth Configuration)
# å®šä¹‰å“ªäº›é¡¹ç›®å®é™…ä¸ŠåŒ…å«æ¼æ´ (Positive Samples)ã€‚
# å¦‚æœä½ çš„æµ‹è¯•é›†å…¨éƒ¨æ˜¯æ— æ¼æ´æ ·æœ¬ï¼ˆç”¨äºæµ‹è¯•è¯¯æŠ¥ç‡ï¼‰ï¼Œè¯·ä¿æŒä¸ºç©ºé›†åˆã€‚
VULNERABLE_PROJECTS = {
    # ç¤ºä¾‹: "0x4e15361fd6b4bb609fa63c81a2be19d873717870_eth",
}

# é»˜è®¤æ ‡ç­¾ (å¦‚æœé¡¹ç›®ä¸åœ¨ä¸Šé¢çš„åˆ—è¡¨ä¸­ï¼Œé»˜è®¤ä¸ºå®‰å…¨/Negative)
DEFAULT_IS_VULNERABLE = False


# =============================================================

def get_ground_truth(project_name):
    """æ ¹æ®é…ç½®åˆ¤æ–­è¯¥é¡¹ç›®å®é™…ä¸Šæ˜¯å¦æœ‰æ¼æ´"""
    if project_name in VULNERABLE_PROJECTS:
        return True  # Positive (Vulnerable)
    return DEFAULT_IS_VULNERABLE  # Negative (Safe)


def calculate_metrics(tp, fp, tn, fn):
    """è®¡ç®— Paper 1 æ‰€éœ€çš„åˆ†ç±»æŒ‡æ ‡"""
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
    total = tp + fp + tn + fn
    accuracy = (tp + tn) / total if total > 0 else 0.0
    return precision, recall, f1, accuracy


def generate_report():
    if not os.path.exists(INPUT_OUTPUT_DIR):
        print(f"âŒ Error: æ‰¾ä¸åˆ°ç›®å½• {INPUT_OUTPUT_DIR}")
        return

    print(f"ğŸ“‚ æ­£åœ¨è¯»å–ç›®å½•: {INPUT_OUTPUT_DIR}")

    try:
        all_files = os.listdir(INPUT_OUTPUT_DIR)
        metadata_files = [f for f in all_files if f.endswith(".metadata.json")]
    except Exception as e:
        print(f"âŒ è¯»å–ç›®å½•å¤±è´¥: {e}")
        return

    print(f"ğŸ” æ‰¾åˆ° {len(metadata_files)} ä¸ªæ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹å…¨é‡è§£æ...")

    # --- ç»Ÿè®¡è®¡æ•°å™¨ ---
    stats = {
        "TP": 0, "FP": 0, "TN": 0, "FN": 0,
        "Total_Time": 0.0,
        "Total_Cost": 0.0,
        "Total_Files": 0,
        "Success_Count": 0,
        "Fail_Count": 0,
        "Total_LOC": 0
    }

    rows = []

    # --- éå†æ–‡ä»¶ ---
    for meta_file in metadata_files:
        meta_path = os.path.join(INPUT_OUTPUT_DIR, meta_file)
        main_json_file = meta_file.replace(".metadata.json", "")
        main_json_path = os.path.join(INPUT_OUTPUT_DIR, main_json_file)

        # æå–é¡¹ç›®å
        if meta_file.startswith("output_") and meta_file.endswith(".json.metadata.json"):
            project_name = meta_file[7:-19]
        else:
            project_name = meta_file

        # åˆå§‹åŒ–è¡Œæ•°æ® (åŒ…å«ä¸¤ä»½ CSV çš„æ‰€æœ‰å­—æ®µ)
        row_data = {
            "Project Name": project_name,
            "Success": "Unknown",  # Paper 2: Robustness
            "Real_Label": "",  # Paper 1: Ground Truth
            "Classification": "",  # Paper 1: TP/FP...
            "Final_Reports": 0,  # Paper 2: Detection/Noise
            "Time(s)": 0.0,  # Paper 2: Performance
            "Cost($)": 0.0,  # Paper 1: Economic
            "LOC": 0,  # Paper 2: Scale
            "Files": 0,
            "Contracts": 0,
            "Initial_Warns": 0,  # Process Metric
            "Static_Filtered": 0,  # Process Metric
            "Vuln_Types": "",  # Paper 2: Scope
            "Message": ""  # Error Log
        }

        try:
            # 1. è¯»å– Metadata (ç»Ÿè®¡æ•°æ®)
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
                row_data["LOC"] = meta.get("loc", 0)
                row_data["Files"] = meta.get("files", 0)
                row_data["Contracts"] = meta.get("contracts", 0)
                row_data["Time(s)"] = meta.get("used_time", 0.0)
                row_data["Cost($)"] = meta.get("estimated_cost", 0.0)

                vul_before = meta.get("vul_before_static", 0)
                vul_after = meta.get("vul_after_static", 0)  # ä¸­é—´æ€
                vul_final = meta.get("vul_after_merge", 0)

                row_data["Initial_Warns"] = vul_before
                row_data["Static_Filtered"] = vul_before - vul_after
                row_data["Final_Reports"] = vul_final

                # ç´¯åŠ ç»Ÿè®¡
                stats["Total_Time"] += row_data["Time(s)"]
                stats["Total_Cost"] += row_data["Cost($)"]
                stats["Total_LOC"] += row_data["LOC"]
                stats["Total_Files"] += 1

            # 2. è¯»å– Main JSON (çŠ¶æ€ä¸è¯¦æƒ…)
            if os.path.exists(main_json_path):
                with open(main_json_path, 'r', encoding='utf-8') as f:
                    main = json.load(f)

                    # é²æ£’æ€§çŠ¶æ€
                    success = main.get("success", False)
                    row_data["Success"] = str(success)
                    if success:
                        stats["Success_Count"] += 1
                    else:
                        stats["Fail_Count"] += 1
                        row_data["Message"] = main.get("message", "Unknown Error")

                    # æå–æ¼æ´ç±»å‹ (Paper 2 Scope)
                    results = main.get("results", [])
                    types = set()
                    for res in results:
                        if isinstance(res, str):
                            types.add(res)
                        elif isinstance(res, dict):
                            # å°è¯•è·å–æ¼æ´åç§°å­—æ®µï¼Œè¿™é‡Œå‡è®¾æ˜¯ 'vulnerability' æˆ– 'name'
                            v_name = res.get("vulnerability", res.get("name", "Unknown"))
                            types.add(v_name)
                    row_data["Vuln_Types"] = "; ".join(types)
            else:
                row_data["Success"] = "False"
                row_data["Message"] = "Main JSON Missing"
                stats["Fail_Count"] += 1

            # 3. è‡ªåŠ¨åˆ†ç±»é€»è¾‘ (TP/FP/TN/FN)
            is_really_vulnerable = get_ground_truth(project_name)
            has_ai_warning = row_data["Final_Reports"] > 0

            if is_really_vulnerable:
                row_data["Real_Label"] = "Vulnerable"
                if has_ai_warning:
                    row_data["Classification"] = "TP"
                    stats["TP"] += 1
                else:
                    row_data["Classification"] = "FN"
                    stats["FN"] += 1
            else:
                row_data["Real_Label"] = "Safe"
                if has_ai_warning:
                    row_data["Classification"] = "FP"
                    stats["FP"] += 1
                else:
                    row_data["Classification"] = "TN"
                    stats["TN"] += 1

            rows.append(row_data)

        except Exception as e:
            print(f"âš ï¸ è§£æé”™è¯¯ {project_name}: {e}")

    # --- è®¡ç®—æœ€ç»ˆæŒ‡æ ‡ ---
    precision, recall, f1, accuracy = calculate_metrics(
        stats["TP"], stats["FP"], stats["TN"], stats["FN"]
    )
    avg_time = stats["Total_Time"] / stats["Total_Files"] if stats["Total_Files"] > 0 else 0
    success_rate = stats["Success_Count"] / stats["Total_Files"] if stats["Total_Files"] > 0 else 0

    # --- å†™å…¥ CSV ---
    # å®šä¹‰è¡¨å¤´ (æ‰€æœ‰è¯¦ç»†åˆ—)
    headers = [
        "Project Name", "Success", "Real_Label", "Classification",
        "Final_Reports", "Vuln_Types",
        "Time(s)", "Cost($)",
        "LOC", "Files", "Contracts",
        "Initial_Warns", "Static_Filtered", "Message"
    ]

    try:
        with open(RESULT_CSV_PATH, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.writer(csvfile)

            # 1. å†™å…¥ä¸»è¡¨å¤´
            writer.writerow(headers)
            # å†™å…¥æ¯ä¸€è¡Œæ•°æ®
            for r in rows:
                writer.writerow([r[h] for h in headers])

            # 2. å†™å…¥åˆ†éš”ç©ºè¡Œ
            writer.writerow([])
            writer.writerow([])

            # 3. å†™å…¥æ±‡æ€»æŠ¥å‘Š (Metrics Summary)
            writer.writerow(["=== ğŸ“Š Final Metrics Summary (æ±‡æ€»æŠ¥å‘Š) ===", "", ""])
            writer.writerow(["Metric (å‚æ•°)", "Value (æ•°å€¼)", "Detailed Explanation (è¯¦ç»†è§£é‡Š)"])

            # Paper 1 Metrics
            writer.writerow(["F1 Score", f"{f1:.2%}",
                             "Paper 1 æ ¸å¿ƒæŒ‡æ ‡ã€‚ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°ï¼Œç»¼åˆè¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚å…¬å¼: 2*(P*R)/(P+R)ã€‚"])
            writer.writerow(
                ["Precision", f"{precision:.2%}", "ç²¾ç¡®ç‡ã€‚æ‰€æœ‰è¢«æŠ¥å‘Šä¸ºæœ‰æ¼æ´çš„åˆçº¦ä¸­ï¼Œç¡®å®æœ‰æ¼æ´çš„æ¯”ä¾‹ã€‚è¡¡é‡æŠ—è¯¯æŠ¥èƒ½åŠ›ã€‚"])
            writer.writerow(
                ["Recall", f"{recall:.2%}", "å¬å›ç‡ (ä¹Ÿç§° Detection Rate)ã€‚æ‰€æœ‰çœŸå®æœ‰æ¼æ´çš„åˆçº¦ä¸­ï¼Œè¢«æˆåŠŸæ£€æµ‹å‡ºçš„æ¯”ä¾‹ã€‚"])
            writer.writerow(["Accuracy", f"{accuracy:.2%}", "å‡†ç¡®ç‡ã€‚æ¨¡å‹åˆ¤æ–­æ­£ç¡®(åŒ…æ‹¬TPå’ŒTN)çš„æ ·æœ¬å æ€»æ ·æœ¬çš„æ¯”ä¾‹ã€‚"])
            writer.writerow(
                ["Total Cost", f"${stats['Total_Cost']:.4f}", "ç»æµæˆæœ¬ã€‚è°ƒç”¨ LLM API (å¦‚ GPT-4) æ‰€æ¶ˆè€—çš„æ€»è´¹ç”¨ã€‚"])

            # Paper 2 Metrics
            writer.writerow(["Avg Time", f"{avg_time:.2f}s",
                             "Paper 2 æ ¸å¿ƒæŒ‡æ ‡ (æ•ˆç‡)ã€‚å¹³å‡æ¯ä¸ªé¡¹ç›®çš„åˆ†æè€—æ—¶ã€‚å¯¹æ¯”æ ‡å‡†: Slither(~5s), Mythril(~84s)ã€‚"])
            writer.writerow(
                ["Success Rate", f"{success_rate:.2%}", "Paper 2 æ ¸å¿ƒæŒ‡æ ‡ (é²æ£’æ€§)ã€‚å·¥å…·æˆåŠŸå®Œæˆåˆ†ææœªå´©æºƒçš„æ¯”ä¾‹ã€‚"])
            writer.writerow(["Total LOC", stats["Total_LOC"], "ä»£ç è§„æ¨¡ã€‚æµ‹è¯•é›†ä¸­åŒ…å«çš„ Solidity ä»£ç æ€»è¡Œæ•°ã€‚"])

            # Raw Counts
            writer.writerow(["True Positives (TP)", stats["TP"], "æ­£ç¡®æ£€æµ‹ã€‚å®é™…ä¸Šæœ‰æ¼æ´ä¸”å·¥å…·æˆåŠŸæŠ¥å‡ºã€‚"])
            writer.writerow(["False Positives (FP)", stats["FP"], "è¯¯æŠ¥ (å™ªéŸ³)ã€‚å®é™…ä¸Šå®‰å…¨ä½†å·¥å…·æŠ¥å‡ºæœ‰æ¼æ´ã€‚"])
            writer.writerow(["True Negatives (TN)", stats["TN"], "æ­£ç¡®å¿½ç•¥ã€‚å®é™…ä¸Šå®‰å…¨ä¸”å·¥å…·æœªæŠ¥æ¼æ´ã€‚"])
            writer.writerow(["False Negatives (FN)", stats["FN"], "æ¼æŠ¥ã€‚å®é™…ä¸Šæœ‰æ¼æ´ä½†å·¥å…·æœªèƒ½æ£€å‡ºã€‚"])

            # 4. å†™å…¥æ•°æ®å­—å…¸ (Data Dictionary / Glossary)
            writer.writerow([])
            writer.writerow(["=== ğŸ“– Column Glossary (å‚æ•°è¯¦ç»†è§£é‡Šå­—å…¸) ===", "", ""])
            writer.writerow(["Column Name (åˆ—å)", "-", "Detailed Explanation (å‚æ•°è§£é‡Š)"])

            glossary = [
                ("Project Name", "è¢«æµ‹è¯•çš„æ™ºèƒ½åˆçº¦é¡¹ç›®åç§°æˆ–å“ˆå¸Œå€¼ã€‚"),
                ("Success", "é²æ£’æ€§çŠ¶æ€ã€‚True è¡¨ç¤ºå·¥å…·å®Œæ•´è¿è¡Œç»“æŸï¼ŒFalse è¡¨ç¤ºè¿è¡Œä¸­é€”å´©æºƒæˆ–è¶…æ—¶ã€‚"),
                ("Real_Label", "Ground Truth (çœŸå€¼)ã€‚æ ¹æ®é…ç½®é¢„è®¾çš„æ ‡ç­¾ï¼Œ'Vulnerable' è¡¨ç¤ºçœŸå®æœ‰æ¯’ï¼Œ'Safe' è¡¨ç¤ºçœŸå®å®‰å…¨ã€‚"),
                ("Classification", "åˆ†ç±»ç»“æœã€‚TP(çœŸé˜³æ€§), FP(è¯¯æŠ¥), TN(çœŸé˜´æ€§), FN(æ¼æŠ¥)ã€‚ç”¨äºè®¡ç®— F1 åˆ†æ•°ã€‚"),
                ("Final_Reports",
                 "æœ€ç»ˆæŠ¥å‘Šæ•°é‡ã€‚ç»è¿‡é™æ€åˆ†æè¿‡æ»¤åï¼ŒAI æœ€ç»ˆè®¤å®šçš„æ¼æ´æ•°é‡ã€‚åœ¨å®‰å…¨æ ·æœ¬æµ‹è¯•ä¸­ï¼Œæ­¤å€¼å¤§äº0å³ä¸ºè¯¯æŠ¥ã€‚"),
                ("Vuln_Types",
                 "æ¼æ´ç±»å‹ã€‚å·¥å…·æ£€æµ‹å‡ºçš„å…·ä½“æ¼æ´ç±»åˆ« (å¦‚ Reentrancy, Arithmetic)ï¼Œç”¨äºè¯„ä¼° Paper 2 çš„æ£€æµ‹èŒƒå›´ (Scope)ã€‚"),
                ("Time(s)", "æ‰§è¡Œæ—¶é—´ã€‚ä»å¯åŠ¨åˆ†æåˆ°ç”ŸæˆæŠ¥å‘Šçš„æ€»è€—æ—¶ (ç§’)ã€‚"),
                ("Cost($)", "é¢„ä¼°æˆæœ¬ã€‚åŸºäº Token æ¶ˆè€—è®¡ç®—çš„ API è´¹ç”¨ã€‚"),
                ("LOC", "Lines of Codeã€‚åˆçº¦çš„ä»£ç è¡Œæ•°ï¼Œè¡¡é‡é¡¹ç›®å¤æ‚åº¦å’Œè§„æ¨¡ã€‚"),
                ("Files / Contracts", "æ–‡ä»¶æ•° / åˆçº¦æ•°ã€‚é¡¹ç›®çš„ç»“æ„å¤æ‚åº¦æŒ‡æ ‡ã€‚"),
                ("Initial_Warns", "åˆå§‹è­¦æŠ¥ã€‚LLM åœ¨ç¬¬ä¸€é˜¶æ®µï¼ˆæœªç»“åˆé™æ€åˆ†æå‰ï¼‰äº§ç”Ÿçš„åŸå§‹æ€€ç–‘æ•°é‡ã€‚"),
                ("Static_Filtered", "è¿‡æ»¤æ•°é‡ã€‚è¢«é™æ€åˆ†æå¼•æ“ï¼ˆå¦‚ Slither éªŒè¯ï¼‰æ’é™¤æ‰çš„ AI è¯¯æŠ¥æ•°é‡ã€‚"),
                ("Message", "é”™è¯¯æ—¥å¿—ã€‚å¦‚æœ Success ä¸º Falseï¼Œæ­¤å¤„è®°å½•å´©æºƒåŸå› ã€‚")
            ]

            for item in glossary:
                writer.writerow([item[0], "-", item[1]])

        print(f"\nâœ… ç»ˆææŠ¥å‘Šå·²ç”Ÿæˆ: {os.path.abspath(RESULT_CSV_PATH)}")
        print(f"ğŸ“Š F1 Score: {f1:.2%}")
        print(f"ğŸš€ Avg Time: {avg_time:.2f}s")

    except Exception as e:
        print(f"âŒ å†™å…¥ CSV å¤±è´¥: {e}")


if __name__ == "__main__":
    generate_report()